{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of 04_NER_using_spaCy_CoNLL.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sandeep16064/Named-Entity-Recognition-NER-Papers/blob/master/model%20of%2004_NER_using_spaCy_CoNLL.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q5D0DhOQwTwq"
      },
      "source": [
        "# Training and Evaluating an NER model with spaCy on the CoNLL dataset\n",
        "\n",
        "In this notebook, we will take a look at using spaCy commandline to train and evaluate a NER model. We will also compare it with the pretrained NER model in spacy. \n",
        "\n",
        "Note: we will create multiple folders during this experiment:\n",
        "spacyNER_data "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AMQsjIY_wTwu"
      },
      "source": [
        "## Step 1: Converting data to json structures so it can be used by Spacy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0ENm_PG8wTwu"
      },
      "source": [
        "import os"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 142
        },
        "id": "bvKsy7lSwTwv",
        "outputId": "02621a5c-c367-4458-a77c-793f75278179"
      },
      "source": [
        "# upload train.txt, test.txt, valid.txt from Data/conll2003/en\n",
        "try:\n",
        "    from google.colab import files\n",
        "    uploaded = files.upload()\n",
        "except ModuleNotFoundError:\n",
        "    print('Not using colab')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-ed8ac496-b54f-4eb3-9c38-addb99993852\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-ed8ac496-b54f-4eb3-9c38-addb99993852\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving dev.txt to dev.txt\n",
            "Saving test.txt to test.txt\n",
            "Saving train.txt to train (1).txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g-KC1D-ZwTwx",
        "outputId": "b412a308-cdcc-4e86-de55-0214fc0c096f"
      },
      "source": [
        "#Read the CONLL data from conll2003 folder, and store the formatted data into a folder spacyNER_data\n",
        "\n",
        "# !mkdir spacyNER_data\n",
        "os.mkdir('spacyNER_data')\n",
        "        \n",
        "#the above lines create folder if it doesn't exist. If it does, the output shows a message that it\n",
        "#already exists and cannot be created again\n",
        "try:\n",
        "    import google.colab \n",
        "    !python -m spacy convert \"train.txt\" spacyNER_data -c ner\n",
        "    !python -m spacy convert \"test.txt\" spacyNER_data -c ner\n",
        "    !python -m spacy convert \"dev.txt\" spacyNER_data -c ner\n",
        "except ModuleNotFoundError:\n",
        "    !python -m spacy convert \"Data/conll2003/en/train.txt\" spacyNER_data -c ner\n",
        "    !python -m spacy convert \"Data/conll2003/en/test.txt\" spacyNER_data -c ner\n",
        "    !python -m spacy convert \"Data/conll2003/en/dev.txt\" spacyNER_data -c ner"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[38;5;4mℹ Auto-detected token-per-line NER format\u001b[0m\n",
            "\u001b[38;5;4mℹ Grouping every 1 sentences into a document.\u001b[0m\n",
            "\u001b[38;5;3m⚠ To generate better training data, you may want to group sentences\n",
            "into documents with `-n 10`.\u001b[0m\n",
            "\u001b[38;5;2m✔ Generated output file (14987 documents): spacyNER_data/train.json\u001b[0m\n",
            "\u001b[38;5;4mℹ Auto-detected token-per-line NER format\u001b[0m\n",
            "\u001b[38;5;4mℹ Grouping every 1 sentences into a document.\u001b[0m\n",
            "\u001b[38;5;3m⚠ To generate better training data, you may want to group sentences\n",
            "into documents with `-n 10`.\u001b[0m\n",
            "\u001b[38;5;2m✔ Generated output file (3466 documents): spacyNER_data/test.json\u001b[0m\n",
            "\u001b[38;5;4mℹ Auto-detected token-per-line NER format\u001b[0m\n",
            "\u001b[38;5;4mℹ Grouping every 1 sentences into a document.\u001b[0m\n",
            "\u001b[38;5;3m⚠ To generate better training data, you may want to group sentences\n",
            "into documents with `-n 10`.\u001b[0m\n",
            "\u001b[38;5;2m✔ Generated output file (3466 documents): spacyNER_data/dev.json\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SMI4n0JywTwx"
      },
      "source": [
        "#### For example, the data before and after running spacy's convert program looks as follows."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X4wBa1MGwTwy",
        "outputId": "8f988bda-25bb-499c-db3c-b931ba0786d7"
      },
      "source": [
        "try:\n",
        "    import google.colab\n",
        "    !echo \"BEFORE : (train.txt)\"\n",
        "    !head \"train.txt\" -n 11 | tail -n 9\n",
        "except ModuleNotFoundError:\n",
        "    print(\"BEFORE : (Data/conll2003/en/train.txt)\")\n",
        "    file = open(\"Data/conll2003/en/train.txt\")\n",
        "    content = file.readlines()\n",
        "    print(*content[1:11])"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BEFORE : (train.txt)\n",
            "EU NNP B-NP B-ORG\n",
            "rejects VBZ B-VP O\n",
            "German JJ B-NP B-MISC\n",
            "call NN I-NP O\n",
            "to TO B-VP O\n",
            "boycott VB I-VP O\n",
            "British JJ B-NP B-MISC\n",
            "lamb NN I-NP O\n",
            ". . O O\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oDYEtB09wTwy",
        "outputId": "453a0e90-d996-4a77-b8da-e978fa348987"
      },
      "source": [
        "try:\n",
        "    import google.colab\n",
        "    !echo \"AFTER : (spacyNER_data/train.json)\"\n",
        "    !head \"spacyNER_data/train.json\" -n 77 | tail -n 58\n",
        "except ModuleNotFoundError:\n",
        "    print(\"AFTER : (spacyNER_data/train.json)\")\n",
        "    f = open('spacyNER_data/train.json')\n",
        "    content = f.readlines()\n",
        "    print(*content[19:77])"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AFTER : (spacyNER_data/train.json)\n",
            "  {\n",
            "    \"id\":1,\n",
            "    \"paragraphs\":[\n",
            "      {\n",
            "        \"sentences\":[\n",
            "          {\n",
            "            \"tokens\":[\n",
            "              {\n",
            "                \"orth\":\"EU\",\n",
            "                \"tag\":\"NNP\",\n",
            "                \"ner\":\"U-ORG\"\n",
            "              },\n",
            "              {\n",
            "                \"orth\":\"rejects\",\n",
            "                \"tag\":\"VBZ\",\n",
            "                \"ner\":\"O\"\n",
            "              },\n",
            "              {\n",
            "                \"orth\":\"German\",\n",
            "                \"tag\":\"JJ\",\n",
            "                \"ner\":\"U-MISC\"\n",
            "              },\n",
            "              {\n",
            "                \"orth\":\"call\",\n",
            "                \"tag\":\"NN\",\n",
            "                \"ner\":\"O\"\n",
            "              },\n",
            "              {\n",
            "                \"orth\":\"to\",\n",
            "                \"tag\":\"TO\",\n",
            "                \"ner\":\"O\"\n",
            "              },\n",
            "              {\n",
            "                \"orth\":\"boycott\",\n",
            "                \"tag\":\"VB\",\n",
            "                \"ner\":\"O\"\n",
            "              },\n",
            "              {\n",
            "                \"orth\":\"British\",\n",
            "                \"tag\":\"JJ\",\n",
            "                \"ner\":\"U-MISC\"\n",
            "              },\n",
            "              {\n",
            "                \"orth\":\"lamb\",\n",
            "                \"tag\":\"NN\",\n",
            "                \"ner\":\"O\"\n",
            "              },\n",
            "              {\n",
            "                \"orth\":\".\",\n",
            "                \"tag\":\".\",\n",
            "                \"ner\":\"O\"\n",
            "              }\n",
            "            ]\n",
            "          }\n",
            "        ]\n",
            "      }\n",
            "    ]\n",
            "  },\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bqDOcC5OwTwz"
      },
      "source": [
        "## Training the NER model with Spacy (CLI)\n",
        "\n",
        "All the commandline options can be seen at: https://spacy.io/api/cli#train\n",
        "We are training using the train program in spacy, for English (en), and the results are stored in a folder \n",
        "called \"model\" (created while training). Our training file is in \"spacyNER_data/train.json\" and the validation file is at: \"spacyNER_data/valid.json\". \n",
        "\n",
        "-G stands for gpu option.\n",
        "-p stands for pipeline, and it should be followed by a comma separated set of options - in this case, a tagger and an NER are being trained simultaneously"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QCmQLlwAwTw0",
        "outputId": "eb9f46ff-b088-4076-c561-6f124e216e29"
      },
      "source": [
        "!python -m spacy train en model spacyNER_data/train.json spacyNER_data/dev.json -G -p tagger,ner"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[38;5;2m✔ Created output directory: model\u001b[0m\n",
            "Training pipeline: ['tagger', 'ner']\n",
            "Starting with blank model 'en'\n",
            "Counting training words (limit=0)\n",
            "/usr/lib/python3.7/runpy.py:193: UserWarning: [W022] Training a new part-of-speech tagger using a model with no lemmatization rules or data. This means that the trained model may not be able to lemmatize correctly. If this is intentional or the language you're using doesn't have lemmatization data, you can ignore this warning by setting SPACY_WARNING_IGNORE=W022. If this is surprising, make sure you have the spacy-lookups-data package installed.\n",
            "  \"__main__\", mod_spec)\n",
            "\n",
            "Itn  Tag Loss    Tag %    NER Loss   NER P   NER R   NER F   Token %  CPU WPS\n",
            "---  ---------  --------  ---------  ------  ------  ------  -------  -------\n",
            "  1  31411.855    94.143  16692.765  83.458  82.868  83.162  100.000    12182\n",
            "  2  16916.010    94.819   7588.607  86.702  86.133  86.416  100.000    12355\n",
            "  3  13723.936    95.130   5222.184  88.040  87.462  87.750  100.000    12042\n",
            "  4  11705.437    95.308   3899.803  88.289  87.799  88.043  100.000    12375\n",
            "  5  10372.514    95.302   3016.821  88.227  88.034  88.131  100.000    12296\n",
            "  6   9653.006    95.391   2564.013  88.445  87.984  88.214  100.000    12308\n",
            "  7   8948.312    95.455   2221.047  88.468  88.051  88.259  100.000    12321\n",
            "  8   8299.700    95.498   1969.310  88.695  88.068  88.380  100.000    12414\n",
            "  9   7895.707    95.585   1745.215  88.547  88.085  88.315  100.000    12304\n",
            " 10   7633.046    95.527   1721.363  88.750  88.152  88.450  100.000    12224\n",
            " 11   7171.104    95.568   1553.392  88.573  88.051  88.311  100.000    12278\n",
            " 12   6734.302    95.523   1484.614  88.616  88.169  88.392  100.000    12285\n",
            " 13   6536.026    95.519   1370.677  88.529  87.933  88.230  100.000    12280\n",
            " 14   6212.412    95.537   1301.030  88.412  87.698  88.053  100.000    12339\n",
            " 15   5968.780    95.574   1268.889  88.757  87.950  88.352  100.000    12312\n",
            "\u001b[38;5;2m✔ Saved model to output directory\u001b[0m\n",
            "model/model-final\n",
            "\u001b[2K\u001b[38;5;2m✔ Created best model\u001b[0m\n",
            "model/model-best\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.7/runpy.py\", line 193, in _run_module_as_main\n",
            "    \"__main__\", mod_spec)\n",
            "  File \"/usr/lib/python3.7/runpy.py\", line 85, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/spacy/__main__.py\", line 33, in <module>\n",
            "    plac.call(commands[command], sys.argv[1:])\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/plac_core.py\", line 367, in call\n",
            "    cmd, result = parser.consume(arglist)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/plac_core.py\", line 232, in consume\n",
            "    return cmd, self.func(*(args + varargs + extraopts), **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/spacy/cli/train.py\", line 415, in train\n",
            "    losses=losses,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/spacy/language.py\", line 519, in update\n",
            "    proc.update(docs, golds, sgd=get_grads, losses=losses, **kwargs)\n",
            "  File \"nn_parser.pyx\", line 462, in spacy.syntax.nn_parser.Parser.update\n",
            "  File \"_parser_model.pyx\", line 246, in spacy.syntax._parser_model.ParserModel.begin_update.finish_parser_update\n",
            "  File \"_parser_model.pyx\", line 392, in spacy.syntax._parser_model.ParserStepModel.make_updates\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/thinc/neural/_classes/feed_forward.py\", line 53, in continue_update\n",
            "    gradient = callback(gradient, sgd)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/thinc/api.py\", line 300, in finish_update\n",
            "    d_X = bp_layer(layer.ops.flatten(d_seqs_out, pad=pad), sgd=sgd)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/thinc/neural/_classes/feed_forward.py\", line 53, in continue_update\n",
            "    gradient = callback(gradient, sgd)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/thinc/neural/_classes/resnet.py\", line 41, in residual_bwd\n",
            "    dX = bp_y(d_output, sgd)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/thinc/neural/_classes/feed_forward.py\", line 53, in continue_update\n",
            "    gradient = callback(gradient, sgd)\n",
            "  File \"ops.pyx\", line 128, in thinc.neural.ops.Ops.dropout.wrap_backprop.finish_update\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/thinc/neural/_classes/layernorm.py\", line 78, in finish_update\n",
            "    return backprop_child(d_xhat, sgd)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/thinc/neural/_classes/maxout.py\", line 86, in finish_update\n",
            "    d_W = self.ops.gemm(dX__bop, X__bi, trans1=True)\n",
            "KeyboardInterrupt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NWj_XbNtwTw0"
      },
      "source": [
        "Notice how the performance improves with each iteration!\n",
        "## Evaluating the model with test data set (`spacyNER_data/test.json`)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2_zTrgq2wTw1"
      },
      "source": [
        "### On Trained model (`model/model-best`)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dxuTnZoVwTw1",
        "outputId": "0b4deb6d-9983-4ad4-a142-6b7ecbe611b5"
      },
      "source": [
        "#create a folder to store the output and visualizations. \n",
        "# !mkdir result\n",
        "os.mkdir('result')\n",
        "!python -m spacy evaluate model/model-best spacyNER_data/test.json -dp result\n",
        "# !python -m spacy evaluate model/model-final data/test.txt.json -dp result"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m\n",
            "================================== Results ==================================\u001b[0m\n",
            "\n",
            "Time      4.29 s\n",
            "Words     51578 \n",
            "Words/s   12024 \n",
            "TOK       100.00\n",
            "POS       95.59 \n",
            "UAS       0.00  \n",
            "LAS       0.00  \n",
            "NER P     88.75 \n",
            "NER R     88.15 \n",
            "NER F     88.45 \n",
            "Textcat   0.00  \n",
            "\n",
            "/usr/lib/python3.7/runpy.py:193: UserWarning: [W006] No entities to visualize found in Doc object. If this is surprising to you, make sure the Doc was processed using a model that supports named entity recognition, and check the `doc.ents` property manually if necessary.\n",
            "  \"__main__\", mod_spec)\n",
            "/usr/lib/python3.7/runpy.py:193: UserWarning: [W006] No entities to visualize found in Doc object. If this is surprising to you, make sure the Doc was processed using a model that supports named entity recognition, and check the `doc.ents` property manually if necessary.\n",
            "  \"__main__\", mod_spec)\n",
            "/usr/lib/python3.7/runpy.py:193: UserWarning: [W006] No entities to visualize found in Doc object. If this is surprising to you, make sure the Doc was processed using a model that supports named entity recognition, and check the `doc.ents` property manually if necessary.\n",
            "  \"__main__\", mod_spec)\n",
            "/usr/lib/python3.7/runpy.py:193: UserWarning: [W006] No entities to visualize found in Doc object. If this is surprising to you, make sure the Doc was processed using a model that supports named entity recognition, and check the `doc.ents` property manually if necessary.\n",
            "  \"__main__\", mod_spec)\n",
            "/usr/lib/python3.7/runpy.py:193: UserWarning: [W006] No entities to visualize found in Doc object. If this is surprising to you, make sure the Doc was processed using a model that supports named entity recognition, and check the `doc.ents` property manually if necessary.\n",
            "  \"__main__\", mod_spec)\n",
            "/usr/lib/python3.7/runpy.py:193: UserWarning: [W006] No entities to visualize found in Doc object. If this is surprising to you, make sure the Doc was processed using a model that supports named entity recognition, and check the `doc.ents` property manually if necessary.\n",
            "  \"__main__\", mod_spec)\n",
            "\u001b[38;5;2m✔ Generated 25 parses as HTML\u001b[0m\n",
            "result\n",
            "\n",
            "\u001b[38;5;1m✘ Evaluation data not found\u001b[0m\n",
            "data/test.json\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4DHk91sbwTw1"
      },
      "source": [
        "a Visualization of the entity tagged test data can be seen in result/entities.html folder. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZRGGHohpwTw2"
      },
      "source": [
        "### On spacy's Pretrained NER model (`en_core_web_sm`)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T0gCT9f-iwjN",
        "outputId": "77040bdd-5958-4b2b-d61a-7de116992b74"
      },
      "source": [
        "!python -m spacy download en_core_web_sm"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting en_core_web_sm==2.2.5\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.2.5/en_core_web_sm-2.2.5.tar.gz (12.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 12.0 MB 5.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: spacy>=2.2.2 in /usr/local/lib/python3.7/dist-packages (from en_core_web_sm==2.2.5) (2.2.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (57.4.0)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.1.3)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (0.9.1)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (4.64.0)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.6)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (3.0.6)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (2.23.0)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.5)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.21.6)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.0)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (7.4.0)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (0.4.1)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (2.0.6)\n",
            "Requirement already satisfied: importlib-metadata>=0.20 in /usr/local/lib/python3.7/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (4.11.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.8.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (4.1.1)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (2021.10.8)\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the model via spacy.load('en_core_web_sm')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MMnN80NDwTw2",
        "outputId": "b888058c-84f4-4852-c1f3-ce8a6360730d"
      },
      "source": [
        "# !mkdir pretrained_result\n",
        "os.mkdir('pretrained_result')\n",
        "!python -m spacy evaluate en_core_web_sm spacyNER_data/test.json -dp pretrained_result"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m\n",
            "================================== Results ==================================\u001b[0m\n",
            "\n",
            "Time      7.77 s\n",
            "Words     51578 \n",
            "Words/s   6637  \n",
            "TOK       100.00\n",
            "POS       87.09 \n",
            "UAS       0.00  \n",
            "LAS       0.00  \n",
            "NER P     5.15  \n",
            "NER R     7.17  \n",
            "NER F     5.99  \n",
            "Textcat   0.00  \n",
            "\n",
            "/usr/lib/python3.7/runpy.py:193: UserWarning: [W006] No entities to visualize found in Doc object. If this is surprising to you, make sure the Doc was processed using a model that supports named entity recognition, and check the `doc.ents` property manually if necessary.\n",
            "  \"__main__\", mod_spec)\n",
            "\u001b[38;5;2m✔ Generated 25 parses as HTML\u001b[0m\n",
            "pretrained_result\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6GiGnqnpwTw3"
      },
      "source": [
        "a Visualization of the entity tagged test data can be seen in pretrained_result/entities.html folder. "
      ]
    }
  ]
}